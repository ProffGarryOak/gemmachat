
# ğŸ§  GemmaChat â€” Personal AI Assistant with API Key & Credit-Based Access

**GemmaChat** is a personal AI assistant powered by **FastAPI** and **Ollama**, running the **Gemma 1B model** locally. It features a secure, scalable architecture with a **credit-based usage system**, ideal for monetized APIs or limited-access tools.

> Built for devs who want full control over AI prompt routing, session context, and user-level API access â€” without external cloud dependencies.

---

## ğŸš€ Features

- ğŸ¤– Runs **Gemma 1B** locally using **Ollama** for fast LLM responses.
- ğŸ” Secure **API key-based authentication** with environment variable config.
- ğŸ’³ Integrated **credit-based access control** â€” each API key has its own usage quota.
- ğŸ“Š Tracks usage per request and updates remaining credits in real-time.
- âš ï¸ Sends **frontend usage alerts** when credits run low.
- ğŸ” Includes **recharge routes and admin logic** to restore credits manually or programmatically.
- ğŸ§© Modular backend structure â€” easily extend to other models or features.

---

## ğŸ“ Folder Structure


```
gemmachat/
â”œâ”€â”€ _mygpt_backend_fastapi/ # FastAPI backend with Gemma integration
â”‚ â”œâ”€â”€ pycache/
â”‚ â”œâ”€â”€ main.py # FastAPI app entrypoint
â”‚ â””â”€â”€ requirements.txt # Python dependencies
â”‚
â”œâ”€â”€ mygptfe/ # Next.js frontend (GemmaChat UI)
â”‚ â”œâ”€â”€ app/ # Page routing and layout
â”‚ â”œâ”€â”€ components/ # Reusable React components
â”‚ â”œâ”€â”€ lib/ # Utility libraries (API handlers, helpers)
â”‚ â”œâ”€â”€ public/ # Static assets (icons, images)
â”‚ â”œâ”€â”€ .gitignore
â”‚ â”œâ”€â”€ README.md
â”‚ â”œâ”€â”€ eslint.config.mjs
â”‚ â”œâ”€â”€ jsconfig.json
â”‚ â”œâ”€â”€ next.config.mjs
â”‚ â”œâ”€â”€ package.json
â”‚ â”œâ”€â”€ package-lock.json
â”‚ â””â”€â”€ postcss.config.mjs
â”‚
â”œâ”€â”€ gemmachat.code-workspace # VS Code workspace config
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ package.json
â””â”€â”€ package-lock.json

```

---

## ğŸ§ª Example API Flow

### ğŸ” Authenticate (via API key)
Each request must include a valid API key in headers:
```

GET /chat
Headers:
x-api-key: YOUR\_SECRET\_KEY

```

### ğŸ—¨ï¸ Chat with Gemma 1B
```

POST /chat
Body:
{
"prompt": "What's the capital of France?"
}

```
Returns AI-generated response from Gemma.

### ğŸ’³ Check Remaining Credits
```

GET /status
Headers:
x-api-key: YOUR\_SECRET\_KEY

````

---

## ğŸ”§ Tech Stack

- ğŸš€ FastAPI (backend framework)
- ğŸ§  Ollama (Gemma 1B local model runtime)
- ğŸ”‘ API key management (custom with .env)
- ğŸ§® Credit tracking logic (in-memory / extendable to DB)
- ğŸ” Optional frontend-compatible alerts and credit UI hooks

---

## ğŸ“¦ Setup Instructions

1. **Install Ollama** and pull Gemma model:
   ```bash
   ollama pull gemma:1b
````

2. **Clone the repo & install dependencies**:

   ```bash
   git clone https://github.com/yourusername/gemmachat
   cd gemmachat
   pip install -r requirements.txt
   ```

3. **Configure your `.env`**:

   ```env
   API_KEYS=yourapikey1,yourapikey2
   INITIAL_CREDITS=20
   ```

4. **Run the app**:

   ```bash
   uvicorn app.main:app --reload
   ```

---

## ğŸ§  Use Cases

* Build your own **AI assistant dashboard**
* Create **usage-limited AI APIs** for clients or teammates
* Monetize AI tools with **credit packs**
* Run **offline LLMs locally**, fully self-hosted

---


