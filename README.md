
# ğŸ§  GemmaChat â€” Personal AI Assistant with API Key & Credit-Based Access

**GemmaChat** is a personal AI assistant powered by **FastAPI** and **Ollama**, running the **Gemma 1B model** locally. It features a secure, scalable architecture with a **credit-based usage system**, ideal for monetized APIs or limited-access tools.

> Built for devs who want full control over AI prompt routing, session context, and user-level API access â€” without external cloud dependencies.

---

## ğŸš€ Features

- ğŸ¤– Runs **Gemma 1B** locally using **Ollama** for fast LLM responses.
- ğŸ” Secure **API key-based authentication** with environment variable config.
- ğŸ’³ Integrated **credit-based access control** â€” each API key has its own usage quota.
- ğŸ“Š Tracks usage per request and updates remaining credits in real-time.
- âš ï¸ Sends **frontend usage alerts** when credits run low.
- ğŸ” Includes **recharge routes and admin logic** to restore credits manually or programmatically.
- ğŸ§© Modular backend structure â€” easily extend to other models or features.

---

## ğŸ“ Folder Structure



gemmachat/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # FastAPI entrypoint
â”‚   â”œâ”€â”€ auth.py               # API key authentication
â”‚   â”œâ”€â”€ credit\_system.py      # Credit checking, deduction, recharge
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ chat.py           # Gemma interaction endpoint
â”‚   â”‚   â””â”€â”€ status.py         # Usage check route
â”œâ”€â”€ .env                      # Store API keys & config
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ğŸ§ª Example API Flow

### ğŸ” Authenticate (via API key)
Each request must include a valid API key in headers:
```

GET /chat
Headers:
x-api-key: YOUR\_SECRET\_KEY

```

### ğŸ—¨ï¸ Chat with Gemma 1B
```

POST /chat
Body:
{
"prompt": "What's the capital of France?"
}

```
Returns AI-generated response from Gemma.

### ğŸ’³ Check Remaining Credits
```

GET /status
Headers:
x-api-key: YOUR\_SECRET\_KEY

````

---

## ğŸ”§ Tech Stack

- ğŸš€ FastAPI (backend framework)
- ğŸ§  Ollama (Gemma 1B local model runtime)
- ğŸ”‘ API key management (custom with .env)
- ğŸ§® Credit tracking logic (in-memory / extendable to DB)
- ğŸ” Optional frontend-compatible alerts and credit UI hooks

---

## ğŸ“¦ Setup Instructions

1. **Install Ollama** and pull Gemma model:
   ```bash
   ollama pull gemma:1b
````

2. **Clone the repo & install dependencies**:

   ```bash
   git clone https://github.com/yourusername/gemmachat
   cd gemmachat
   pip install -r requirements.txt
   ```

3. **Configure your `.env`**:

   ```env
   API_KEYS=yourapikey1,yourapikey2
   INITIAL_CREDITS=20
   ```

4. **Run the app**:

   ```bash
   uvicorn app.main:app --reload
   ```

---

## ğŸ§  Use Cases

* Build your own **AI assistant dashboard**
* Create **usage-limited AI APIs** for clients or teammates
* Monetize AI tools with **credit packs**
* Run **offline LLMs locally**, fully self-hosted

---


